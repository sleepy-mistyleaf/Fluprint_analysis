{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transition to Polynomial Regression\n",
    "\n",
    "### Objective\n",
    "\n",
    "We aim to enhance the predictive performance of our model by transitioning from linear to polynomial regression combined with logistic regression. This approach allows us to capture non-linear relationships between features and the target variable (vaccine_response) in the FluPRINT dataset.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "1.  Polynomial Feature Transformation: We use degrees 1 and 2 to test both linear and quadratic relationships.\n",
    "2. Model Evaluation: Cross-validation is performed to evaluate model performance using the F1 macro score.\n",
    "3. Final Model Testing: The best-performing degree is selected and tested on a separate dataset.\n",
    "\n",
    "### Rationale\n",
    "Polynomial regression can better capture complex interactions in the data, potentially improving classification accuracy compared to linear models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1- Setup and Data Loading\n",
    "\n",
    "First, we'll import the required libraries and load our preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_fluprint = r\"C:\\Users\\Dana\\OneDrive\\Documents\\Applied Data science\\FluPRINT_database\\FluPRINT_filtered_data\\aggregated_participants.csv\"\n",
    "fluprint_data = pd.read_csv(path_to_fluprint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Polynomial Regression\n",
    "\n",
    "This code evaluates the performance of polynomial regression combined with logistic regression for predicting vaccine_response using the single feature d_geo_mean, which represents the titre difference between pre- and post-vaccination.\n",
    "\n",
    "Polynomial features are generated for degrees 1 and 2 to compare linear and quadratic relationships. Testing higher-degree polynomials is avoided at this stage to reduce the risk of overfitting, as simpler models are often more generalisable. Cross-validation with 5 folds is used to evaluate model performance, with the F1 macro score chosen as the metric to account for potential class imbalance in the dataset.\n",
    "\n",
    "This process helps determine whether incorporating non-linear relationships improves prediction accuracy compared to a simple linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1 polynomial:\n",
      "Mean F1 score: 0.636 (+/- 0.132)\n",
      "\n",
      "Degree 2 polynomial:\n",
      "Mean F1 score: 0.647 (+/- 0.123)\n",
      "\n",
      "Best polynomial model performance:\n",
      "Accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.82      0.78        38\n",
      "         1.0       0.61      0.52      0.56        21\n",
      "\n",
      "    accuracy                           0.71        59\n",
      "   macro avg       0.68      0.67      0.67        59\n",
      "weighted avg       0.70      0.71      0.71        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = fluprint_data[[\"d_geo_mean\"]]\n",
    "y = fluprint_data[\"vaccine_response\"]\n",
    "\n",
    "degrees = [1,2]\n",
    "\n",
    "for degree in degrees:\n",
    "    poly_model = make_pipeline(\n",
    "        PolynomialFeatures(degree=degree, include_bias=False),\n",
    "        LogisticRegression(class_weight = \"balanced\", max_iter = 1000)\n",
    "    )\n",
    "\n",
    "    scores = cross_val_score(poly_model, X, y, cv=5, scoring = \"f1_macro\")\n",
    "\n",
    "    print(f\"Degree {degree} polynomial:\")\n",
    "    print(f\"Mean F1 score: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n",
    "    print()\n",
    "\n",
    "best_degree = 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "first_poly_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=best_degree, include_bias=False),\n",
    "    LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    ")\n",
    "\n",
    "first_poly_model.fit(X_train, y_train)\n",
    "y_pred = first_poly_model.predict(X_test)\n",
    "\n",
    "print(\"Best polynomial model performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Overview\n",
    "\n",
    "#### Cross-Validation Results\n",
    "- **Degree 1 Polynomial**: Mean F1 score of 0.636 with a margin of error of +/- 0.132.\n",
    "- **Degree 2 Polynomial**: Mean F1 score of 0.647 with a margin of error of +/- 0.123.\n",
    "\n",
    "#### Best Polynomial Model Performance (Degree 2)\n",
    "- **Accuracy**: 0.71\n",
    "- **Class 0.0**: Precision 0.76, Recall 0.82, F1-score 0.78, Support 38.\n",
    "- **Class 1.0**: Precision 0.61, Recall 0.52, F1-score 0.56, Support 21.\n",
    "- **Macro Average**: Precision 0.68, Recall 0.67, F1-score 0.67.\n",
    "- **Weighted Average**: Precision 0.70, Recall 0.71, F1-score 0.71.\n",
    "\n",
    "#### Interpretation\n",
    "The degree 2 polynomial model slightly outperforms the degree 1 model in terms of mean F1 score from cross-validation and also has a similar accuracy to the logistic regression model (*logistic_regression -Step 6*). The model performs better on class 0.0 than on class 1.0, indicating potential class imbalance issues. The macro average F1 score (0.67) is lower than the weighted average (0.71), suggesting that the model's performance is influenced by the class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Polynomial Model with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1 polynomial with SMOTE:\n",
      "Accuracy: 0.76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.89      0.83        38\n",
      "         1.0       0.73      0.52      0.61        21\n",
      "\n",
      "    accuracy                           0.76        59\n",
      "   macro avg       0.75      0.71      0.72        59\n",
      "weighted avg       0.76      0.76      0.75        59\n",
      "\n",
      "Degree 2 polynomial with SMOTE:\n",
      "Accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.82      0.78        38\n",
      "         1.0       0.61      0.52      0.56        21\n",
      "\n",
      "    accuracy                           0.71        59\n",
      "   macro avg       0.68      0.67      0.67        59\n",
      "weighted avg       0.70      0.71      0.71        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "X = fluprint_data[[\"d_geo_mean\"]]\n",
    "y = fluprint_data[\"vaccine_response\"]\n",
    "\n",
    "# Define polynomial degrees to test\n",
    "degrees = [1, 2]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Loop through each degree and evaluate the model\n",
    "for degree in degrees:\n",
    "    # Create polynomial features for resampled training data\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train_resampled)\n",
    "    \n",
    "    # Fit logistic regression on resampled data with polynomial features\n",
    "    clf = LogisticRegression(class_weight=\"balanced\", max_iter=1000)\n",
    "    clf.fit(X_train_poly, y_train_resampled)\n",
    "    \n",
    "    # Evaluate on test data (apply same polynomial transformation)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    y_pred = clf.predict(X_test_poly)\n",
    "    \n",
    "    print(f\"Degree {degree} polynomial with SMOTE:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Performance:\n",
    "- **Accuracy**: 0.76\n",
    "\n",
    "### Class-Specific Performance:\n",
    "- **Low Responders (Class 0):**\n",
    "  - **Recall: 89%**: Good at identifying true low responders. The model is relatively more sensitive to this class.\n",
    "  - **Precision: 77%**: Indicates that some individuals are incorrectly classified as low responders, leading to false positives. \n",
    "- **High Responders (Class 1):**\n",
    "  - **Recall: 52%**: Significantly lower, meaning the model misses a large portion of true high responders.\n",
    "  - **Precision: 73%**: Suggests that when the model *does* predict someone as a high responder, it's more likely to be correct. However, it's not predicting this class frequently enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix using ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**  The model excels at identifying Low Responders but struggles with High Responders.\n",
    "\n",
    "### Key Observations:\n",
    "- **Focus on Recall for High Responders:** The primary issue isn't the *accuracy* of predicting High Responders (precision is decent), but the *frequency* (recall is low). The model is too conservative in predicting this class.\n",
    "- **True Positive Bottleneck:** The model struggles to reliably distinguish true positives (high responders) from false negatives.\n",
    "- **Trade-off Between Classes:** The confusion matrix highlights the trade-off: improving recall for Class 1 likely means accepting more false positives for Class 0.\n",
    "\n",
    "### Why is SMOTE Not Fully Addressing Imbalance?\n",
    "Despite using SMOTE, the imbalance issue persists. Possible reasons:\n",
    "1. **Feature Overlap:** If the features of the minority class (high responders) overlap significantly with the majority class (low responders), SMOTE may generate synthetic samples that are difficult for the model to differentiate. These may effectively add noise and not genuinely improve separability.\n",
    "2. **Data Complexity:** The underlying relationships between features and vaccine response may be more complex than a simple polynomial logistic regression can capture, even with SMOTE-enhanced data.  The limited feature set (`d_geo_mean`) could be a contributing factor, preventing SMOTE from working effectively.\n",
    "3. **SMOTE Limitations:** SMOTE creates synthetic samples by interpolating between existing minority class instances. If the original minority class instances are themselves quite diverse, the generated samples might not accurately represent the full spectrum of high responders.\n",
    "\n",
    "### Next Steps:\n",
    "1. **Adjust Classification Threshold**: Experiment with lower thresholds to increase sensitivity towards high responders.\n",
    "2. **Explore Other Models**: Consider tree-based algorithms or other models more capable of handling imbalanced data and complex relationships.\n",
    "3. **Advanced Resampling**: Look into combining SMOTE with under-sampling techniques (e.g., SMOTE-Tomek links) to potentially remove noisy samples and improve class separation.\n",
    "4. **Feature Importance**: Investigate feature importance to determine if `d_geo_mean` is overshadowing other potential predictors or if additional features are necessary.\n",
    "5. **Further Feature Engineering**: Attempt to generate new features from existing ones to better capture the immune response. Consider the ratio of antibody titers, or differences in other immune markers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Incorporating more features \n",
    "Like in the previous notebook, we will try to improve the model's performance and potentially mitigate class imbalance issues, additional features (`visit_age`, `gender`, and `race`) are included in the model. While these features do not directly address class imbalance, they provide more information that can help the model better distinguish between classes. The use of balanced class weights in logistic regression (`class_weight=\"balanced\"`) is a direct approach to handling class imbalance.\n",
    "\n",
    "**Note:**\n",
    "Considering the last time we have tried this (`logistic_regression Step 7`), the accuracy decreased the accuracy, there is a high likelihood it will do the same in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1 polynomial:\n",
      "Mean F1 score: 0.638 (+/- 0.119)\n",
      "\n",
      "Degree 2 polynomial:\n",
      "Mean F1 score: 0.642 (+/- 0.121)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Dana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best polynomial model performance:\n",
      "Accuracy: 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.76      0.78        38\n",
      "         1.0       0.61      0.67      0.64        21\n",
      "\n",
      "    accuracy                           0.73        59\n",
      "   macro avg       0.71      0.71      0.71        59\n",
      "weighted avg       0.74      0.73      0.73        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select relevant features and one-hot encode categorical variables\n",
    "X = pd.get_dummies(fluprint_data[[\"d_geo_mean\", \"visit_age\", \"gender\", \"race\"]], columns=[\"gender\", \"race\"], drop_first=True)\n",
    "y = fluprint_data[\"vaccine_response\"]\n",
    "\n",
    "# Define the polynomial degrees to test\n",
    "degrees = [1,2]\n",
    "\n",
    "# Loop through each degree and evaluate the model\n",
    "for degree in degrees:\n",
    "    poly_model = make_pipeline(\n",
    "        PolynomialFeatures(degree=degree, include_bias=False),\n",
    "        LogisticRegression(class_weight = \"balanced\")\n",
    "    )\n",
    "\n",
    "    scores = cross_val_score(poly_model, X, y, cv=5, scoring = \"f1_macro\")\n",
    "\n",
    "    print(f\"Degree {degree} polynomial:\")\n",
    "    print(f\"Mean F1 score: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# Select the best polynomial degree based on cross-validation results\n",
    "best_degree = 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "second_poly_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=best_degree, include_bias=False),\n",
    "    LogisticRegression(class_weight='balanced', max_iter=1000, C=0.01)\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "second_poly_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test data\n",
    "y_pred = second_poly_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance on the test set\n",
    "print(\"Best polynomial model performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Performance Breakdown:\n",
    "-   **Low Responders (Class 0):**\n",
    "    *   **Precision: 81%**: When the model predicts a low responder, it's correct 81% of the time.\n",
    "    *   **Recall: 76%**: The model identifies 76% of all actual low responders.\n",
    "\n",
    "-   **High Responders (Class 1):**\n",
    "    *   **Precision: 61%**: When the model predicts a high responder, it's correct 61% of the time.\n",
    "    *   **Recall: 67%**: The model identifies 67% of all actual high responders.\n",
    "\n",
    "### Key Observations & Interpretations:\n",
    "*   **Limited Improvement with Added Features**: Adding demographic features (`visit_age`, `gender`, `race`) did *not* lead to a significant improvement in model performance compared to using only `d_geo_mean`. This may indicate:\n",
    "\n",
    "    1.  **Feature Irrelevance:** The added features are not strong predictors of vaccine response, or they are redundant with `d_geo_mean`.\n",
    "    2.  **Feature Interactions:** The relationship between the features and the target is more complex than the model can capture (e.g., non-linear interactions).\n",
    "\n",
    "*   **Persistent Class Imbalance Challenge:** Despite using `class_weight='balanced'`, the model still struggles to achieve high recall for the minority class (High Responders).\n",
    "\n",
    "*   **Convergence Warnings**: The `ConvergenceWarning` messages suggest that the logistic regression solver did not converge within the maximum iterations. This can be caused by:\n",
    "\n",
    "    1.  **Unscaled Data**: The features have different scales, which can make optimization difficult.\n",
    "    2.  **Multicollinearity:** High correlation between features can cause instability in the optimization process. Polynomial features can exacerbate this.\n",
    "\n",
    "*   **Regularization (C=0.01):** The low value of C indicates strong regularization. Regularization prevents overfitting, but too much may impede the modelâ€™s ability to capture the underlying relationships in the data, especially with interactions from polynomial features.\n",
    "\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "While adding more features seemed like a promising approach, it did not yield a significant improvement in model performance in this case. The model is still struggling with the class imbalance, and there are potential issues with feature scaling and convergence. Focus on data preprocessing, feature selection/engineering, model tuning, and explore alternative models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
